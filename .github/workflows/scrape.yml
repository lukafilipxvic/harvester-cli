name: Scrape Website

on:
  schedule:
    - cron: '0 */6 * * *'  # Run every 6 hours
  workflow_dispatch:  # Allow manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.12'
    
    - name: Install uv
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH
    
    - name: Run scraper script
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LLM_MODEL: ${{ secrets.LLM_MODEL }}
      run: |
        uv run harvester.py -u "ycombinator.com" -s "Website" -o "output.json"
    
    - name: Commit and push if changed
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add output.json
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update scraped data" && git push)